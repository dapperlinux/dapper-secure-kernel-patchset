diff --git a/arch/x86/xen/mmu_pv.c b/arch/x86/xen/mmu_pv.c
index cab28cf..b5c794d 100644
--- a/arch/x86/xen/mmu_pv.c
+++ b/arch/x86/xen/mmu_pv.c
@@ -67,6 +67,7 @@
 #include <asm/init.h>
 #include <asm/pat.h>
 #include <asm/smp.h>
+#include <asm/alternative-asm.h>
 
 #include <asm/xen/hypercall.h>
 #include <asm/xen/hypervisor.h>
@@ -1922,7 +1923,13 @@ void __init xen_setup_kernel_pagetable(pgd_t *pgd, unsigned long max_pfn)
 	/* L3_k[511] -> level2_fixmap_pgt */
 	convert_pfn_mfn(level3_kernel_pgt);
 
-	/* L3_k[511][506] -> level1_fixmap_pgt */
+	convert_pfn_mfn(level3_vmalloc_start_pgt[0]);
+	convert_pfn_mfn(level3_vmalloc_start_pgt[1]);
+	convert_pfn_mfn(level3_vmalloc_start_pgt[2]);
+	convert_pfn_mfn(level3_vmalloc_start_pgt[3]);
+	convert_pfn_mfn(level3_vmalloc_end_pgt);
+	convert_pfn_mfn(level3_vmemmap_pgt);
+	/* L3_k[511][507] -> level1_vsyscall_pgt */
 	convert_pfn_mfn(level2_fixmap_pgt);
 
 	/* We get [511][511] and have Xen's version of level2_kernel_pgt */
@@ -1951,11 +1958,25 @@ void __init xen_setup_kernel_pagetable(pgd_t *pgd, unsigned long max_pfn)
 	set_page_prot(init_top_pgt, PAGE_KERNEL_RO);
 	set_page_prot(level3_ident_pgt, PAGE_KERNEL_RO);
 	set_page_prot(level3_kernel_pgt, PAGE_KERNEL_RO);
+	set_page_prot(level3_vmalloc_start_pgt[0], PAGE_KERNEL_RO);
+	set_page_prot(level3_vmalloc_start_pgt[1], PAGE_KERNEL_RO);
+	set_page_prot(level3_vmalloc_start_pgt[2], PAGE_KERNEL_RO);
+	set_page_prot(level3_vmalloc_start_pgt[3], PAGE_KERNEL_RO);
+	set_page_prot(level3_vmalloc_end_pgt, PAGE_KERNEL_RO);
+	set_page_prot(level3_vmemmap_pgt, PAGE_KERNEL_RO);
 	set_page_prot(level3_user_vsyscall, PAGE_KERNEL_RO);
 	set_page_prot(level2_ident_pgt, PAGE_KERNEL_RO);
+	set_page_prot(level2_vmemmap_pgt, PAGE_KERNEL_RO);
 	set_page_prot(level2_kernel_pgt, PAGE_KERNEL_RO);
 	set_page_prot(level2_fixmap_pgt, PAGE_KERNEL_RO);
-	set_page_prot(level1_fixmap_pgt, PAGE_KERNEL_RO);
+	set_page_prot(level1_modules_pgt[0], PAGE_KERNEL_RO);
+	set_page_prot(level1_modules_pgt[1], PAGE_KERNEL_RO);
+	set_page_prot(level1_modules_pgt[2], PAGE_KERNEL_RO);
+	set_page_prot(level1_modules_pgt[3], PAGE_KERNEL_RO);
+	set_page_prot(level1_fixmap_pgt[0], PAGE_KERNEL_RO);
+	set_page_prot(level1_fixmap_pgt[1], PAGE_KERNEL_RO);
+	set_page_prot(level1_fixmap_pgt[2], PAGE_KERNEL_RO);
+	set_page_prot(level1_vsyscall_pgt, PAGE_KERNEL_RO);
 
 	/* Pin down new L4 */
 	pin_pagetable_pfn(MMUEXT_PIN_L4_TABLE,
@@ -2389,6 +2410,7 @@ static void __init xen_post_allocator_init(void)
 	pv_mmu_ops.set_pud = xen_set_pud;
 #if CONFIG_PGTABLE_LEVELS >= 4
 	pv_mmu_ops.set_p4d = xen_set_p4d;
+	pv_mmu_ops.set_p4d_batched = xen_set_p4d;
 #endif
 
 	/* This will work as long as patching hasn't happened yet
@@ -2401,7 +2423,7 @@ static void __init xen_post_allocator_init(void)
 	pv_mmu_ops.alloc_pud = xen_alloc_pud;
 	pv_mmu_ops.release_pud = xen_release_pud;
 #endif
-	pv_mmu_ops.make_pte = PV_CALLEE_SAVE(xen_make_pte);
+	pv_mmu_ops.make_pte = PV_CALLEE_SAVE(make_pte, xen_make_pte);
 
 #ifdef CONFIG_X86_64
 	pv_mmu_ops.write_cr3 = &xen_write_cr3;
@@ -2418,6 +2440,10 @@ static void xen_leave_lazy_mmu(void)
 	preempt_enable();
 }
 
+static void xen_pte_update(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
+{
+}
+
 static const struct pv_mmu_ops xen_mmu_ops __initconst = {
 	.read_cr2 = xen_read_cr2,
 	.write_cr2 = xen_write_cr2,
@@ -2430,7 +2456,7 @@ static const struct pv_mmu_ops xen_mmu_ops __initconst = {
 	.flush_tlb_single = xen_flush_tlb_single,
 	.flush_tlb_others = xen_flush_tlb_others,
 
-	.pte_update = paravirt_nop,
+	.pte_update = xen_pte_update,
 
 	.pgd_alloc = xen_pgd_alloc,
 	.pgd_free = xen_pgd_free,
@@ -2447,11 +2473,11 @@ static const struct pv_mmu_ops xen_mmu_ops __initconst = {
 	.ptep_modify_prot_start = __ptep_modify_prot_start,
 	.ptep_modify_prot_commit = __ptep_modify_prot_commit,
 
-	.pte_val = PV_CALLEE_SAVE(xen_pte_val),
-	.pgd_val = PV_CALLEE_SAVE(xen_pgd_val),
+	.pte_val = PV_CALLEE_SAVE(pte_val, xen_pte_val),
+	.pgd_val = PV_CALLEE_SAVE(pgd_val, xen_pgd_val),
 
-	.make_pte = PV_CALLEE_SAVE(xen_make_pte_init),
-	.make_pgd = PV_CALLEE_SAVE(xen_make_pgd),
+	.make_pte = PV_CALLEE_SAVE(make_pte, xen_make_pte_init),
+	.make_pgd = PV_CALLEE_SAVE(make_pgd, xen_make_pgd),
 
 #ifdef CONFIG_X86_PAE
 	.set_pte_atomic = xen_set_pte_atomic,
@@ -2460,13 +2486,14 @@ static const struct pv_mmu_ops xen_mmu_ops __initconst = {
 #endif	/* CONFIG_X86_PAE */
 	.set_pud = xen_set_pud_hyper,
 
-	.make_pmd = PV_CALLEE_SAVE(xen_make_pmd),
-	.pmd_val = PV_CALLEE_SAVE(xen_pmd_val),
+	.make_pmd = PV_CALLEE_SAVE(make_pmd, xen_make_pmd),
+	.pmd_val = PV_CALLEE_SAVE(pmd_val, xen_pmd_val),
 
 #if CONFIG_PGTABLE_LEVELS >= 4
-	.pud_val = PV_CALLEE_SAVE(xen_pud_val),
-	.make_pud = PV_CALLEE_SAVE(xen_make_pud),
+	.pud_val = PV_CALLEE_SAVE(pud_val, xen_pud_val),
+	.make_pud = PV_CALLEE_SAVE(make_pud, xen_make_pud),
 	.set_p4d = xen_set_p4d_hyper,
+	.set_p4d_batched = xen_set_p4d_hyper,
 
 	.alloc_pud = xen_alloc_pmd_init,
 	.release_pud = xen_release_pmd_init,
