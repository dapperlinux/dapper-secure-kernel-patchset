diff --git a/arch/x86/kernel/head64.c b/arch/x86/kernel/head64.c
index b5785c1..c60cbcf 100644
--- a/arch/x86/kernel/head64.c
+++ b/arch/x86/kernel/head64.c
@@ -38,6 +38,13 @@ extern pmd_t early_dynamic_pgts[EARLY_DYNAMIC_PAGE_TABLES][PTRS_PER_PMD];
 static unsigned int __initdata next_early_pgt;
 pmdval_t early_pmd_flags = __PAGE_KERNEL_LARGE & ~(_PAGE_GLOBAL | _PAGE_NX);
 
+#define L4_VMALLOC_START	pgd_index(VMALLOC_START)
+#define L3_VMALLOC_START	pud_index(VMALLOC_START)
+#define L4_VMALLOC_END		pgd_index(VMALLOC_END)
+#define L3_VMALLOC_END		pud_index(VMALLOC_END)
+#define L4_VMEMMAP_START	pgd_index(VMEMMAP_START)
+#define L3_VMEMMAP_START	pud_index(VMEMMAP_START)
+
 #define __head	__section(.head.text)
 
 static void __head *fixup_pointer(void *ptr, unsigned long physaddr)
@@ -74,18 +81,48 @@ void __head __startup_64(unsigned long physaddr)
 	pgd = fixup_pointer(&early_top_pgt, physaddr);
 	pgd[pgd_index(__START_KERNEL_map)] += load_delta;
 
+	pgd = fixup_pointer(&init_level4_pgt, physaddr);
+	pgd[L4_PAGE_OFFSET] += load_delta;
+	pgd[L4_VMALLOC_START] += load_delta;
+	pgd[L4_VMALLOC_START + 1] += load_delta;
+	pgd[L4_VMALLOC_START + 2] += load_delta;
+	pgd[L4_VMALLOC_START + 3] += load_delta;
+	pgd[L4_VMALLOC_END] += load_delta;
+	pgd[L4_VMEMMAP_START] += load_delta;
+	pgd[L4_START_KERNEL] += load_delta;
+
 	if (IS_ENABLED(CONFIG_X86_5LEVEL)) {
 		p4d = fixup_pointer(&level4_kernel_pgt, physaddr);
 		p4d[511] += load_delta;
 	}
 
+	pud = fixup_pointer(&level3_ident_pgt, physaddr);
+	pud[0] += load_delta;
+#ifndef CONFIG_XEN
+	pud[1] += load_delta;
+#endif
+
+	pud = fixup_pointer(&level3_vmemmap_pgt, physaddr);
+	pud[L3_VMEMMAP_START] += load_delta;
+
 	pud = fixup_pointer(&level3_kernel_pgt, physaddr);
-	pud[510] += load_delta;
-	pud[511] += load_delta;
+	pud[L3_START_KERNEL] += load_delta;
+	pud[L3_START_KERNEL + 1] += load_delta;
+
+	pmd = fixup_pointer(level2_ident_pgt, physaddr);
+	pmd[0] += load_delta;
 
 	pmd = fixup_pointer(level2_fixmap_pgt, physaddr);
-	pmd[506] += load_delta;
+	pmd[0] += load_delta;
+	pmd[1] += load_delta;
+	pmd[2] += load_delta;
+	pmd[2] += load_delta;
 
+	pmd[504] += load_delta;
+	pmd[505] += load_delta;
+	pmd[506] += load_delta;
+	pmd[507] += load_delta;
+ 
 	/*
 	 * Set up the identity mapping for the switchover.  These
 	 * entries should *NOT* have the global bit set!  This also
@@ -168,14 +168,14 @@ int __init early_make_pgtable(unsigned long address)
 	pgd = *pgd_p;
 
 	/*
-	 * The use of __START_KERNEL_map rather than __PAGE_OFFSET here is
-	 * critical -- __PAGE_OFFSET would point us back into the dynamic
+	 * The use of __early_va rather than __va here is critical:
+	 * __va would point us back into the dynamic
 	 * range and we might end up looping forever...
 	 */
 	if (!IS_ENABLED(CONFIG_X86_5LEVEL))
 		p4d_p = pgd_p;
 	else if (pgd)
-		p4d_p = (p4dval_t *)((pgd & PTE_PFN_MASK) + __START_KERNEL_map - phys_base);
+		p4d_p = (p4dval_t *)(__early_va(pgd & PTE_PFN_MASK));
 	else {
 		if (next_early_pgt >= EARLY_DYNAMIC_PAGE_TABLES) {
 			reset_early_page_tables();
@@ -184,7 +184,7 @@ int __init early_make_pgtable(unsigned long address)
 
 		p4d_p = (p4dval_t *)early_dynamic_pgts[next_early_pgt++];
 		memset(p4d_p, 0, sizeof(*p4d_p) * PTRS_PER_P4D);
-		*pgd_p = (pgdval_t)p4d_p - __START_KERNEL_map + phys_base + _KERNPG_TABLE;
+		*pgd_p = (pgdval_t)__pa(p4d_p) + _KERNPG_TABLE;
 	}
 	p4d_p += p4d_index(address);
 	p4d = *p4d_p;
@@ -199,13 +199,13 @@ int __init early_make_pgtable(unsigned long address)
 
 		pud_p = (pudval_t *)early_dynamic_pgts[next_early_pgt++];
 		memset(pud_p, 0, sizeof(*pud_p) * PTRS_PER_PUD);
-		*p4d_p = (p4dval_t)pud_p - __START_KERNEL_map + phys_base + _KERNPG_TABLE;
+		*p4d_p = (p4dval_t)__pa(pud_p) + _KERNPG_TABLE;
 	}
 	pud_p += pud_index(address);
 	pud = *pud_p;
 
 	if (pud)
-		pmd_p = (pmdval_t *)((pud & PTE_PFN_MASK) + __START_KERNEL_map - phys_base);
+		pmd_p = (pmdval_t *)(__early_va(pud & PTE_PFN_MASK));
 	else {
 		if (next_early_pgt >= EARLY_DYNAMIC_PAGE_TABLES) {
 			reset_early_page_tables();
@@ -92,7 +92,7 @@ int __init early_make_pgtable(unsigned long address)
 
 		pmd_p = (pmdval_t *)early_dynamic_pgts[next_early_pgt++];
 		memset(pmd_p, 0, sizeof(*pmd_p) * PTRS_PER_PMD);
-		*pud_p = (pudval_t)pmd_p - __START_KERNEL_map + phys_base + _KERNPG_TABLE;
+		*pud_p = (pudval_t)__pa(pmd_p) + _KERNPG_TABLE;
 	}
 	pmd = (physaddr & PMD_MASK) + early_pmd_flags;
 	pmd_p[pmd_index(address)] = pmd;
@@ -278,8 +278,6 @@ asmlinkage __visible void __init x86_64_start_kernel(char * real_mode_data)
 
 	clear_bss();
 
-	clear_page(init_top_pgt);
-
 	kasan_early_init();
 
 	for (i = 0; i < NUM_EXCEPTION_VECTORS; i++)
