diff --git a/include/linux/sched/task.h b/include/linux/sched/task.h
index a978d71..7e644c0 100644
--- a/include/linux/sched/task.h
+++ b/include/linux/sched/task.h
@@ -65,7 +65,7 @@ static inline void exit_thread(struct task_struct *tsk)
 {
 }
 #endif
-extern void do_group_exit(int);
+extern __noreturn void do_group_exit(int);
 
 extern void exit_files(struct task_struct *);
 extern void exit_itimers(struct signal_struct *);
@@ -99,11 +99,106 @@ struct task_struct *try_get_task_struct(struct task_struct **ptask);
 
 
 #ifdef CONFIG_ARCH_WANTS_DYNAMIC_TASK_STRUCT
-extern int arch_task_struct_size __read_mostly;
+extern size_t arch_task_struct_size __read_mostly;
 #else
 # define arch_task_struct_size (sizeof(struct task_struct))
 #endif
 
+#define MF_PAX_PAGEEXEC		0x01000000	/* Paging based non-executable pages */
+#define MF_PAX_EMUTRAMP		0x02000000	/* Emulate trampolines */
+#define MF_PAX_MPROTECT		0x04000000	/* Restrict mprotect() */
+#define MF_PAX_RANDMMAP		0x08000000	/* Randomize mmap() base */
+/*#define MF_PAX_RANDEXEC		0x10000000*/	/* Randomize ET_EXEC base */
+#define MF_PAX_SEGMEXEC		0x20000000	/* Segmentation based non-executable pages */
+
+#ifdef CONFIG_PAX_SOFTMODE
+extern int pax_softmode;
+#endif
+
+extern int pax_check_flags(unsigned long *);
+#define PAX_PARSE_FLAGS_FALLBACK	(~0UL)
+
+/* if tsk != current then task_lock must be held on it */
+#if defined(CONFIG_PAX_NOEXEC) || defined(CONFIG_PAX_ASLR)
+static inline unsigned long pax_get_flags(struct task_struct *tsk)
+{
+	if (likely(tsk->mm))
+		return tsk->mm->pax_flags;
+	else
+		return 0UL;
+}
+
+/* if tsk != current then task_lock must be held on it */
+static inline long pax_set_flags(struct task_struct *tsk, unsigned long flags)
+{
+	if (likely(tsk->mm)) {
+		tsk->mm->pax_flags = flags;
+		return 0;
+	}
+	return -EINVAL;
+}
+#endif
+
+#ifdef CONFIG_PAX_HAVE_ACL_FLAGS
+extern void pax_set_initial_flags(struct linux_binprm *bprm);
+#elif defined(CONFIG_PAX_HOOK_ACL_FLAGS)
+extern void (*pax_set_initial_flags_func)(struct linux_binprm *bprm);
+#endif
+
+#ifdef CONFIG_PAX_SIZE_OVERFLOW
+extern bool pax_size_overflow_report_only;
+#endif
+
+struct path;
+extern char *pax_get_path(const struct path *path, char *buf, int buflen);
+extern void pax_report_fault(struct pt_regs *regs, void *pc, void *sp);
+extern void pax_report_insns(struct pt_regs *regs, void *pc, void *sp);
+extern void pax_report_refcount_error(struct pt_regs *regs, const char *kind);
+
+#ifdef CONFIG_GRKERNSEC_KSTACKOVERFLOW
+static inline void populate_stack(void *stack, unsigned int size)
+{
+	int c;
+	int *ptr = stack;
+	int *end = stack + size;
+
+	while (ptr < end) {
+		c = *(volatile int *)ptr;
+		(void)c;
+		ptr += PAGE_SIZE/sizeof(int);
+	}
+}
+#else
+static inline void populate_stack(void *stack, unsigned int size)
+{
+}
+#endif
+
+const void *gr_convert_stack_address_to_lowmem(const void *buf);
+
+#ifdef CONFIG_GRKERNSEC
+static inline bool current_is_ptracer(struct task_struct *task, u64 *exec_id)
+{
+	bool ret = false;
+        if (!task->ptrace)
+		return ret;
+
+	rcu_read_lock();
+	read_lock(&tasklist_lock);
+	if (task->parent && task->parent == current) {
+		ret = true;
+#ifdef CONFIG_GRKERNSEC_PROC_MEMMAP
+		if (exec_id)
+			*exec_id = task->parent->exec_id;
+#endif
+	}
+	read_unlock(&tasklist_lock);
+	rcu_read_unlock();
+
+	return ret;
+}
+#endif
+
 #ifdef CONFIG_VMAP_STACK
 static inline struct vm_struct *task_stack_vm_area(const struct task_struct *t)
 {
@@ -126,11 +221,13 @@ static inline struct vm_struct *task_stack_vm_area(const struct task_struct *t)
  * It must not be nested with write_lock_irq(&tasklist_lock),
  * neither inside nor outside.
  */
+static inline void task_lock(struct task_struct *p) __acquires(&p->alloc_lock);
 static inline void task_lock(struct task_struct *p)
 {
 	spin_lock(&p->alloc_lock);
 }
 
+static inline void task_unlock(struct task_struct *p) __releases(&p->alloc_lock);
 static inline void task_unlock(struct task_struct *p)
 {
 	spin_unlock(&p->alloc_lock);
